{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "from copy import deepcopy\n",
    "from utils import remove_file_or_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of whisper models and support languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_models = [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
    "source_languages = {\n",
    "    \"en\": \"English\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"fi\": \"Finnish\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"he\": \"Hebrew\",\n",
    "    \"uk\": \"Ukrainian\",\n",
    "    \"el\": \"Greek\",\n",
    "    \"ms\": \"Malay\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"ta\": \"Tamil\",\n",
    "    \"no\": \"Norwegian\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"ur\": \"Urdu\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"lt\": \"Lithuanian\",\n",
    "    \"la\": \"Latin\",\n",
    "    \"mi\": \"Maori\",\n",
    "    \"ml\": \"Malayalam\",\n",
    "    \"cy\": \"Welsh\",\n",
    "    \"sk\": \"Slovak\",\n",
    "    \"te\": \"Telugu\",\n",
    "    \"fa\": \"Persian\",\n",
    "    \"lv\": \"Latvian\",\n",
    "    \"bn\": \"Bengali\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"az\": \"Azerbaijani\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"kn\": \"Kannada\",\n",
    "    \"et\": \"Estonian\",\n",
    "    \"mk\": \"Macedonian\",\n",
    "    \"br\": \"Breton\",\n",
    "    \"eu\": \"Basque\",\n",
    "    \"is\": \"Icelandic\",\n",
    "    \"hy\": \"Armenian\",\n",
    "    \"ne\": \"Nepali\",\n",
    "    \"mn\": \"Mongolian\",\n",
    "    \"bs\": \"Bosnian\",\n",
    "    \"kk\": \"Kazakh\",\n",
    "    \"sq\": \"Albanian\",\n",
    "    \"sw\": \"Swahili\",\n",
    "    \"gl\": \"Galician\",\n",
    "    \"mr\": \"Marathi\",\n",
    "    \"pa\": \"Punjabi\",\n",
    "    \"si\": \"Sinhala\",\n",
    "    \"km\": \"Khmer\",\n",
    "    \"sn\": \"Shona\",\n",
    "    \"yo\": \"Yoruba\",\n",
    "    \"so\": \"Somali\",\n",
    "    \"af\": \"Afrikaans\",\n",
    "    \"oc\": \"Occitan\",\n",
    "    \"ka\": \"Georgian\",\n",
    "    \"be\": \"Belarusian\",\n",
    "    \"tg\": \"Tajik\",\n",
    "    \"sd\": \"Sindhi\",\n",
    "    \"gu\": \"Gujarati\",\n",
    "    \"am\": \"Amharic\",\n",
    "    \"yi\": \"Yiddish\",\n",
    "    \"lo\": \"Lao\",\n",
    "    \"uz\": \"Uzbek\",\n",
    "    \"fo\": \"Faroese\",\n",
    "    \"ht\": \"Haitian creole\",\n",
    "    \"ps\": \"Pashto\",\n",
    "    \"tk\": \"Turkmen\",\n",
    "    \"nn\": \"Nynorsk\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"sa\": \"Sanskrit\",\n",
    "    \"lb\": \"Luxembourgish\",\n",
    "    \"my\": \"Myanmar\",\n",
    "    \"bo\": \"Tibetan\",\n",
    "    \"tl\": \"Tagalog\",\n",
    "    \"mg\": \"Malagasy\",\n",
    "    \"as\": \"Assamese\",\n",
    "    \"tt\": \"Tatar\",\n",
    "    \"haw\": \"Hawaiian\",\n",
    "    \"ln\": \"Lingala\",\n",
    "    \"ha\": \"Hausa\",\n",
    "    \"ba\": \"Bashkir\",\n",
    "    \"jw\": \"Javanese\",\n",
    "    \"su\": \"Sundanese\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_file(segments, out_filepath):\n",
    "    remove_file_or_dir(out_filepath)\n",
    "    with open(out_filepath, \"w+\") as f:\n",
    "        csv_writer = csv.writer(f, delimiter=\",\")\n",
    "        for segment in segments:\n",
    "            csv_writer.writerow([segment.start, segment.end, segment.text])\n",
    "    return out_filepath\n",
    "\n",
    "\n",
    "def speech_to_text(audio_file, language=\"vi\", out_dir=\"data/texts/\"):\n",
    "    # Run on GPU with FP16\n",
    "    model_size = \"medium\"\n",
    "    # model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", download_root=\"model\", local_files_only=True)\n",
    "    print(f\"Using Whisper model version {model_size}\")\n",
    "    # or run on GPU with INT8\n",
    "    # model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "    # or run on CPU with INT8\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", download_root=\"models\", local_files_only=True)\n",
    "    # model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(\n",
    "        audio_file,\n",
    "        beam_size=5,\n",
    "        best_of=5,\n",
    "        language=language,\n",
    "        # no_speech_threshold=0.5,\n",
    "        # vad_filter=True,\n",
    "        # vad_parameters=dict(min_silence_duration_ms=500),\n",
    "        # word_timestamps=True,\n",
    "    )\n",
    "\n",
    "    print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "    # for segment in segments:\n",
    "    #     print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "    \n",
    "    filename, ext = os.path.splitext(os.path.basename(f\"{audio_file}\"))\n",
    "    output_file = os.path.join(out_dir, filename + \".csv\")\n",
    "    output_file = export_file(segments, output_file)\n",
    "    print(f\"Output file saved at {output_file}\")\n",
    "    return output_file, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"data/sound/GPT_NEEDED_THIS___DALL-E_3_IS_HERE___YOU_CAN_TRY_IT_FREE.wav\"\n",
    "# _, info = speech_to_text(audio_path, language=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate the text with google translator\n",
    "\n",
    "We can try https://huggingface.co/VietAI/envit5-translation\n",
    "or https://github.com/VinAIResearch/VinAI_Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, target_lang_code=\"vi\", src_lang_code=\"en\"):\n",
    "    translator = Translator()\n",
    "    translated_text = translator.translate(text, dest=target_lang_code).text\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_rows(input_file):\n",
    "    merged_rows = []\n",
    "    # Read the input CSV file\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        # Initialize the first row as the current row\n",
    "        current_row = next(reader)\n",
    "        for row in reader:\n",
    "            # Check if the \"end\" value of the current row is equal to the \"end\" value of the next row\n",
    "            if float(current_row['end']) == float(row['end']):\n",
    "                # Merge the \"text\" values of the current row and the next row\n",
    "                current_row['text'] += row['text']\n",
    "            else:\n",
    "                # Append the merged row to the list\n",
    "                merged_rows.append(current_row)\n",
    "                # Update the current row to the next row\n",
    "                current_row = row\n",
    "        \n",
    "        # Append the last merged row to the list\n",
    "        merged_rows.append(current_row)\n",
    "    return merged_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_consecutive_segments(timestamp_segments_file, epsilon=0.05, out_dir=\"data/merged_texts/\"):\n",
    "    timestamp_segments = pd.read_csv(timestamp_segments_file,\n",
    "                                 names=[\"start\", \"end\", \"text\"])\n",
    "    n_segments = len(timestamp_segments)\n",
    "    merged_segments = []\n",
    "    current_row = timestamp_segments.iloc[0].tolist() #loc[[0]].tolist()\n",
    "    for i in range(0, n_segments -1):\n",
    "        next_row = timestamp_segments.iloc[i+1].tolist()#loc[[i+1]].tolist()\n",
    "        # if start time of next row - end time of previous row < epsilon -> merge it\n",
    "        if float(next_row[0]) - float(current_row[1]) <= epsilon:\n",
    "            current_row[1] = next_row[1]\n",
    "            current_row[2] += next_row[2]\n",
    "        else:\n",
    "            merged_segments.append(current_row)\n",
    "            current_row = next_row\n",
    "    # concat the last row to the list\n",
    "    merged_segments.append(current_row)\n",
    "\n",
    "    file_name = os.path.basename(timestamp_segments_file)\n",
    "    file_path = os.path.join(out_dir, file_name)\n",
    "    remove_file_or_dir(file_path)\n",
    "    with open(file_path, \"w\") as file:\n",
    "        csv_writer = csv.writer(file, delimiter=\",\")\n",
    "        csv_writer.writerows(merged_segments)\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_csv = \"/mnt/d/Projects/video-translation/data/texts/GPT_NEEDED_THIS___DALL-E_3_IS_HERE___YOU_CAN_TRY_IT_FREE.csv\"\n",
    "merged_segments = merge_consecutive_segments(text_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/merged_texts/GPT_NEEDED_THIS___DALL-E_3_IS_HERE___YOU_CAN_TRY_IT_FREE.csv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text from csv\n",
    "def create_translated_speech_csv(speech_csv_filepath, out_dir=\"data/translated_texts\"):\n",
    "    filename = os.path.basename(speech_csv_filepath)\n",
    "    full_text = \"\"\n",
    "    timestamp_segments = pd.read_csv(speech_csv_filepath,\n",
    "                                 names=[\"start\", \"end\", \"text\"])\n",
    "    print(f\"There are {len(timestamp_segments)} segments before translating!\")\n",
    "    # check if there are any empty string\n",
    "    \"\"\"\n",
    "    empty_row_idx = timestamp_text[timestamp_text['text'] == ''].index\n",
    "    if len(empty_row_idx) > 0:\n",
    "        print(f\"There \")\n",
    "    \"\"\"\n",
    "    # get full text\n",
    "    full_text = '|'.join(timestamp_segments[\"text\"][:10])\n",
    "    print(f\"There are {len(full_text.split())} words.\")\n",
    "    # translate the text\n",
    "    trans_full_text = translate_text(full_text)\n",
    "    print(f\"Translated text: {trans_full_text}\")\n",
    "    translated_text_segments = trans_full_text.split(\"|\")\n",
    "    print(f\"There are {len(translated_text_segments)} segments after translating!\")\n",
    "    # timestamp_segments['text'] = translated_text_segments\n",
    "    # save thte translated timestamp speech textt\n",
    "    # timestamp_segments.to_csv(os.path.join(out_dir, filename))\n",
    "    # Writing to CSV file\n",
    "    return timestamp_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_csv = \"/mnt/d/Projects/video-translation/data/texts/GPT_NEEDED_THIS___DALL-E_3_IS_HERE___YOU_CAN_TRY_IT_FREE.csv\"\n",
    "# df_text = create_translated_speech_csv(text_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'end'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Projects/video-translation/3.speech_to_text.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m merged_text \u001b[39m=\u001b[39m merge_csv_rows(text_csv)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(merged_text)\n",
      "\u001b[1;32m/mnt/d/Projects/video-translation/3.speech_to_text.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m current_row \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(reader)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m reader:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# Check if the \"end\" value of the current row is equal to the \"end\" value of the next row\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mfloat\u001b[39m(current_row[\u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m==\u001b[39m \u001b[39mfloat\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m# Merge the \"text\" values of the current row and the next row\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         current_row[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Projects/video-translation/3.speech_to_text.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m# Append the merged row to the list\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'end'"
     ]
    }
   ],
   "source": [
    "merged_text = merge_csv_rows(text_csv)\n",
    "print(merged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidtrans_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
